<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Real-Time STT WebApp</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 20px; }
        #transcript { max-height: 300px; overflow-y: auto; border: 1px solid #ccc; padding: 10px; }
        #status { margin: 10px 0; padding: 5px; }
        .highlight { background-color: yellow; }
        canvas { display: block; margin: 10px 0; }
    </style>
</head>
<body>
    <button id="startBtn">üé§ Start</button>
    <button id="stopBtn" disabled>üõë Stop</button>
    <div id="status">Idle</div>
    <canvas id="visualizer" width="100" height="100"></canvas>
    <div id="transcript"></div>

    <script>
        const startBtn = document.getElementById('startBtn');
        const stopBtn = document.getElementById('stopBtn');
        const statusDiv = document.getElementById('status');
        const transcriptDiv = document.getElementById('transcript');
        const canvas = document.getElementById('visualizer');
        const ctx = canvas.getContext('2d');

        let audioContext, processor, stream, socket, analyser, sessionId;

        // Ïò§ÎîîÏò§ Ï¥àÍ∏∞Ìôî Î∞è Web Audio API ÏÑ§Ï†ï
        async function initAudio() {
            stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            audioContext = new AudioContext({ sampleRate: 16000 });
            const source = audioContext.createMediaStreamSource(stream);
            processor = audioContext.createScriptProcessor(2048, 1, 1);
            analyser = audioContext.createAnalyser(); // ÎÇ¥Ïû• VADÏö© Î∂ÑÏÑùÍ∏∞
            analyser.fftSize = 2048;
            source.connect(analyser);
            analyser.connect(processor);
            processor.connect(audioContext.destination);

            processor.onaudioprocess = (event) => {
                const pcmData = event.inputBuffer.getChannelData(0);
                const int16Data = new Int16Array(pcmData.length);
                for (let i = 0; i < pcmData.length; i++) {
                    int16Data[i] = Math.max(-32768, Math.min(32767, pcmData[i] * 32768));
                }

                // Web Audio API ÎÇ¥Ïû• VAD: Î≥ºÎ•® Í∏∞Î∞ò ÏùåÏÑ± Í∞êÏßÄ
                const buffer = new Float32Array(analyser.frequencyBinCount);
                analyser.getFloatFrequencyData(buffer);
                const volume = Math.max(...pcmData.map(Math.abs));
                const isSpeech = volume > 0.01; // ÏûÑÍ≥ÑÍ∞í 0.01Î°ú ÏùåÏÑ± Í∞êÏßÄ (Ï°∞Ï†ï Í∞ÄÎä•)

                if (isSpeech) {
                    statusDiv.textContent = "Speaking - Speech detected";
                    statusDiv.style.color = "green";
                    if (socket && socket.readyState === WebSocket.OPEN) {
                        socket.send(int16Data.buffer); // ÏùåÏÑ± Í∞êÏßÄ Ïãú Îç∞Ïù¥ÌÑ∞ Ï†ÑÏÜ°
                    }
                } else {
                    statusDiv.textContent = "Listening - Waiting for speech...";
                    statusDiv.style.color = "blue";
                }
                visualizeVolume(pcmData); // Ïã§ÏãúÍ∞Ñ Î≥ºÎ•® ÏãúÍ∞ÅÌôî
            };
        }

        // CanvasÎ°ú ÏùåÏÑ± Î≥ºÎ•® ÏãúÍ∞ÅÌôî
        function visualizeVolume(data) {
            const volume = Math.max(...data.map(Math.abs));
            const radius = 10 + volume * 40; // ÏµúÏÜå 10px, ÏµúÎåÄ 50px
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            ctx.beginPath();
            ctx.arc(50, 50, radius, 0, 2 * Math.PI);
            ctx.fillStyle = "blue";
            ctx.fill();
        }

        // ÏÑ∏ÏÖò ÏÉùÏÑ± Î∞è STT ÏãúÏûë
        startBtn.onclick = async () => {
            try {
                // ÏÑúÎ≤ÑÏóêÏÑú ÏÑ∏ÏÖò ID ÏöîÏ≤≠
                const sessionResponse = await fetch('http://localhost:8000/summa-api/v1/sessions/create', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ user_id: 'user123' }) // ÏûÑÏùò ÏÇ¨Ïö©Ïûê ID
                });
                const sessionData = await sessionResponse.json();
                sessionId = sessionData.session_id;

                await initAudio(); // Ïò§ÎîîÏò§ Ï¥àÍ∏∞Ìôî
                statusDiv.textContent = "Connecting to WebSocket...";
                statusDiv.style.color = "gray";

                // WebSocket Ïó∞Í≤∞
                socket = new WebSocket(`ws://localhost:8000/summa-api/v1/sessions/${sessionId}/ws`);
                socket.onopen = () => {
                    startBtn.disabled = true;
                    stopBtn.disabled = false;
                    statusDiv.textContent = "Listening - Waiting for speech...";
                    statusDiv.style.color = "blue";
                    console.log(`WebSocket connected for session: ${sessionId}`);
                };
                socket.onmessage = (event) => {
                    const text = event.data;
                    const p = document.createElement('p');
                    p.textContent = text;
                    p.classList.add('highlight');
                    transcriptDiv.appendChild(p);
                    transcriptDiv.scrollTop = transcriptDiv.scrollHeight;
                };
                socket.onerror = (error) => {
                    statusDiv.textContent = `Error: WebSocket connection failed`;
                    statusDiv.style.color = "red";
                    console.error("WebSocket error:", error);
                };
                socket.onclose = () => {
                    console.log("WebSocket closed");
                };
            } catch (error) {
                statusDiv.textContent = `Error: ${error.message}`;
                statusDiv.style.color = "red";
                console.error("Start error:", error);
            }
        };

        // STT Ï§ëÏßÄ
        stopBtn.onclick = async () => {
            try {
                stream.getTracks().forEach(track => track.stop());
                processor.disconnect();
                analyser.disconnect();
                audioContext.close();
                if (socket && socket.readyState === WebSocket.OPEN) {
                    socket.close();
                }

                // ÏµúÏ¢Ö ÌÖçÏä§Ìä∏ ÏöîÏ≤≠
                const response = await fetch(`http://localhost:8000/summa-api/v1/sessions/${sessionId}/finalize`, {
                    method: 'POST'
                });
                const finalText = await response.json();
                const p = document.createElement('p');
                p.textContent = `${finalText.timestamp}: ${finalText.text}`;
                transcriptDiv.appendChild(p);

                startBtn.disabled = false;
                stopBtn.disabled = true;
                statusDiv.textContent = "Stopped";
                statusDiv.style.color = "red";
            } catch (error) {
                statusDiv.textContent = `Error: ${error.message}`;
                statusDiv.style.color = "red";
                console.error("Stop error:", error);
            }
        };
    </script>
</body>
</html>